---
layout: post
title: How to Use TACC (Texas Advanced Computing Center) to Facilitate Data Analysis (Ubuntu) 
categories: [Ubuntu]
tags: [ssh, configure, supercomputer]
---

Coming soon!

![](http://i.imgur.com/PSNKgUT.jpg)

Supercomputer is one of the essential tools for bioinformatics, especially encountering the big data,
which will dramatically speed up your work process. TACC ( Texas Advanced Computing Center )
at the University of Texas at Austin, United States, is a research center for advanced computational
science, engineering and technology.
This summer I registered a personal account in TACC and XSEDE ( The Extreme Science and
Engineering Discovery Environment ) and used it involving these aspects:

- 1.Change the config file in the .ssh directory to quickly log in TACC.
- 2.Load modules and transfer files or directories in it from remote distance.
- 3.Write job scripts and submit it.

## How Log in TACC
After registered your account, the most regulator approach to login supercomputer with ssh

```
$ ssh lushen@stampede.tacc.utexas.edu
```
After typing your password, you can enter the supercomputer and use it.
However, the easier way to enter your supercomputer and avoid typing so tedious username is that

```
$ cd .ssh
$ vim config
```
and compile some statements in the config ( after ' # ' are comments)

```
Host=stampede # username that is used to login TACC in your terminal.
Hostname=stampede.tacc.utexas.edu # hostname you registered in your TACC account.
User=lushen # username your registered in your TACC account.
```
After saving that, you can login your supercomputer just use

```
$ ssh stampede
```
How to load Bowtie, Tophat and SAM tools in TACC
After logging into TACC, you should load the softwares you want to use

```
$ moudle load softwareName(eg. bowtie)
```
> Note:
• You should load Bowtie first and Tophat afterwards
• If you have loaded these software but you close your supercomputer once. These software
will disappear at the end. So you need to use the command: module save, which will set
these softwares are default and never disappear unless you want to change that.

After that, you could remotely transfer the files or directories use the command (if you want see the
detials, use the command line: $ man scp (or $ scp --help).

```
$ scp -r /work/fish/shenlu/2-4_cell_2
lushen@stampede.tacc.utexas.edu:/scratch/02473/lushen/temp
```
## How to compile a job scripts and submit it into clusters
### 1. Edit a job scripts (the more details about it: Stampede User Guide )

```
#!/bin/bash
#SBATCH -J myjob1
# job name
#SBATCH -o myjob1.o%j
# output and error file name (%j expands to jobID)
#SBATCH -n 32
# total number of mpi tasks requested
#SBATCH -p normal # queue (partition) -- normal, development, etc.
#SBATCH -t 24:00:00
# run time (hh:mm:ss) - 24.0 hours
#SBATCH --mail-type=end # email me when the job finishes
#The statements below are the commands that you want supercomputer to implement.
tophat -p 16 --library-type fr-unstranded /scratch/02473/lushen/temp/bowtie/zebrafish_index
/scratch/02473/lushen/temp/2-4_cell/2-4_cell_1.fastq /scratch/02473/lushen/temp/2-4_cell/2-
4_cell_2.fastq -G /scratch/02473/lushen/temp/zebrafish_genome/Danio_rerio_annotation
```
### 2. Use 'sbatch' to submit the command line in the cluster of supercomputer

```
$ sbatch job_script_1.txt job_script_2.txt
```
### 3. Show the job that have submitted to check if your edited scripts are submitted

```
$ showq -u
```

### 4. Cancel your job you have submitted

```
$ scancel 870919 870922
```
